# Risk Agent Analyzer Environment Configuration
# Copy this file to .env and configure your settings

# === LLM Configuration ===
LLM_PROVIDER=walmart_gateway
LLM_API_KEY=your_api_key_here
WM_CONSUMER_ID=your_consumer_id
WM_SVC_NAME=your_service_name  
WM_SVC_ENV=production

# === API Endpoints ===
LLM_GATEWAY_URL=https://wmtllmgateway.stage.walmart.com/wmtllmgateway/v1/openai
OPENAI_URL=https://wmtllmgateway.stage.walmart.com/wmtllmgateway/v1/openai

# === Authentication ===
CONSUMER_PEM_FILE_PATH=/path/to/your/private_key.pem
CA_BUNDLE_PATH=/path/to/your/ca_bundle.crt

# === GitHub Configuration ===
GITHUB_TOKEN=ghp_your_github_token_here
GITHUB_API_BASE=https://api.github.com  # For public GitHub
# GITHUB_API_BASE=https://gecgithub01.walmart.com/api/v3  # For GitHub Enterprise

# === Analysis Configuration ===
CODE_REVIEW_MODE=full_repo  # Options: full_repo, pr_only
PR_STATE=open              # Options: open, closed, all
PR_LIMIT=10               # Number of PRs to analyze
OUTPUT_DIR=./reports      # Report output directory

# === Performance & Reliability Settings ===
LLM_TIMEOUT_SECONDS=120   # Timeout for LLM requests (recommended: 120-300 seconds)
LLM_MAX_RETRIES=3        # Number of retry attempts for failed requests
LLM_MAX_TOKENS=1000      # Maximum tokens per LLM response
LLM_TEMPERATURE=0.7      # LLM creativity level (0.0-1.0)

# === Optional Configuration ===
LOG_LEVEL=INFO            # Options: DEBUG, INFO, WARNING, ERROR
TIMEOUT_SECONDS=300       # Analysis timeout
MAX_FILE_SIZE=1048576     # Max file size in bytes (1MB)
LLM_VERIFY_SSL=false     # SSL verification for staging environments

# === Performance Optimization ===
# For high-volume or enterprise usage:
# LLM_TIMEOUT_SECONDS=300  # Increase for complex analysis
# LLM_MAX_RETRIES=5       # More retries for reliability
# PR_LIMIT=50             # Higher PR limit for comprehensive analysis